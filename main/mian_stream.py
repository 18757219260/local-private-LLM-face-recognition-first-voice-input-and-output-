import sys
import os
sys.path.append(os.path.abspath("/home/wuye/vscode/chatbox"))
import asyncio
from qa_model.qa_model_easy import KnowledgeQA
from ASR.asr import ASRhelper
from TTS.tts_stream import TTStreaming
import time
import argparse
import signal
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("chatbox.log"), logging.StreamHandler()]
)

async def main():
    # åˆå§‹åŒ– QA å’Œ TTS
    parser = argparse.ArgumentParser(description="ç”˜è–¯çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    parser.add_argument("--voice", default="zh-CN-XiaoyiNeural", help="TTS voice to use")
    parser.add_argument("--model", default="qwen2.5:7b", help="LLM model to use")
    parser.add_argument("--wait-after-response", type=float, default=1.5, 
                      help="ç­‰å¾…ç­‰æ¨¡å‹è¯´å®Œå†æ¬¡å¼€å§‹ç›‘å¬çš„æ—¶")
    args = parser.parse_args()
    
    # æ§åˆ¶æ˜¯å¦æ­£åœ¨è¯´è¯çš„æ ‡å¿—
    is_speaking = False
    
    try:
        qa = KnowledgeQA(llm_model=args.model)
        tts = TTStreaming(voice=args.voice)
        asr = ASRhelper()
        
        print("ç”˜è–¯çŸ¥è¯†é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼æŒ‰ Ctrl+C é€€å‡º")
        
        # è®¾ç½®ä¼˜é›…å…³é—­
        shutdown_event = asyncio.Event()
        
        def signal_handler(*args):
            print("\næ­£åœ¨å…³é—­ç³»ç»Ÿ...")
            shutdown_event.set()
            
        for sig in (signal.SIGINT, signal.SIGTERM):
            signal.signal(sig, lambda s, f: asyncio.create_task(asyncio.to_thread(signal_handler)))
        
        while not shutdown_event.is_set():
            buffer = ""
            min_length = 5  # æœ€å°æ–‡æœ¬é•¿åº¦
            trigger_length = 40  # è§¦å‘è¯­éŸ³çš„å­—ç¬¦æ•°
            timeout = 0.5  # 0.5ç§’è¶…æ—¶è§¦å‘è¯­éŸ³
            
            # ç¡®ä¿ç³»ç»Ÿä¸åœ¨è¯´è¯æ—¶æ‰å¼€å§‹è¯­éŸ³è¯†åˆ«
            print("\nè¯·å¼€å§‹è¯´è¯...")
            question_result = asr.real_time_recognition()
            
            # æ£€æŸ¥è¯­éŸ³è¯†åˆ«ç»“æœ
            if not question_result or 'result' not in question_result or not question_result['result']:
                print("æ— è¾“å…¥ï¼Œè¯·é‡æ–°å°è¯•")
                await asyncio.sleep(1)
                continue
            
            question = question_result["result"][0]
            print(f"ç”¨æˆ·é—®é¢˜: {question}")
            
            # æ£€æµ‹ç‰¹æ®Šå‘½ä»¤
            if question.lower() in ["é€€å‡º", "å…³é—­", "åœæ­¢"]:
                print("æ”¶åˆ°é€€å‡ºæŒ‡ä»¤")
                break
            
            # è®¾ç½®æ­£åœ¨è¯´è¯æ ‡å¿—
            is_speaking = True
            tts_complete_event = asyncio.Event()
            
            # æ–‡æœ¬ç”Ÿæˆå™¨
            async def text_producer():
                try:
                    async for chunk in qa.ask_stream(question):
                        print(f"ğŸ§  è¾“å‡ºå—: {chunk}")
                        yield chunk
                except Exception as e:
                    logging.error(f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}")
                    yield "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚"
            
            # æ–‡æœ¬å¤„ç†å’ŒTTS
            async def text_consumer():
                nonlocal buffer
                last_chunk_time = time.time()
                chunks_received = False
                
                try:
                    async for chunk in text_producer():
                        chunks_received = True
                        chunk = tts.preprocess_text(chunk)
                        buffer += chunk
                        last_chunk_time = time.time()
                        
                        # è§¦å‘è¯­éŸ³ï¼šè¾¾åˆ°æŒ‡å®šé•¿åº¦æˆ–è¶…æ—¶
                        if len(buffer) >= trigger_length or (time.time() - last_chunk_time) >= timeout:
                            if len(buffer) >= min_length:
                                segment = buffer
                                buffer = ""
                                print(f"è¯­éŸ³è¾“å‡º: {segment}")
                                await tts.speak(segment)  # ç§»é™¤'11'å‰ç¼€ï¼Œé™¤éç¡®å®éœ€è¦
                    
                    # å¤„ç†å‰©ä½™æ–‡æœ¬
                    if buffer and len(buffer) >= min_length:
                        print(f"è¯­éŸ³è¾“å‡ºï¼ˆå‰©ä½™ï¼‰: {buffer}")
                        await tts.speak(buffer)  # ç§»é™¤'11'å‰ç¼€
                    
                    # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•å†…å®¹
                    if not chunks_received:
                        await tts.speak("æŠ±æ­‰ï¼Œæˆ‘æ²¡èƒ½æ‰¾åˆ°ç›¸å…³çš„ç”˜è–¯çŸ¥è¯†ã€‚")
                        
                except Exception as e:
                    logging.error(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™: {e}")
                    await tts.speak("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ã€‚")
                finally:
                    # æ— è®ºå¦‚ä½•éƒ½éœ€è¦é‡ç½®çŠ¶æ€
                    tts_complete_event.set()
            
            # æ‰§è¡Œæ–‡æœ¬æ¶ˆè´¹è€…ä»»åŠ¡
            await text_consumer()
            
            # æ ‡è®°è¯­éŸ³å·²ç»“æŸ
            is_speaking = False
            
            # ç­‰å¾…é¢å¤–çš„æ—¶é—´ï¼Œç¡®ä¿ç”¨æˆ·æœ‰æ—¶é—´ç†è§£å“åº”
            logging.info(f"ç­‰å¾… {args.wait_after_response} ç§’åå†æ¬¡å¼€å§‹ç›‘å¬...")
            await asyncio.sleep(args.wait_after_response)
            
    except Exception as e:
        logging.error(f"ç³»ç»Ÿè¿è¡Œæ—¶å‡ºé”™: {e}")
    finally:
        # æ¸…ç†èµ„æº
        try:
            await tts.shutdown()
            asr.stop_recording()
            print("ç¨‹åºå·²å®‰å…¨é€€å‡ºï¼Œèµ„æºå·²æ¸…ç†")
        except Exception as e:
            logging.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())