import asyncio
import edge_tts
import subprocess
import io
import logging
from collections import deque
from qa_model_easy import KnowledgeQA
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(), logging.FileHandler("chat.log")]
)

class EdgeTTSStreaming:
    def __init__(self, voice="zh-CN-XiaoyiNeural"):
        self.voice = voice
        self.is_speaking = False
        self.audio_queue = asyncio.Queue()
        self.mpg123_process = None
        self.min_buffer_size = 6400

    def preprocess_text(self, text):
        """
        é¢„å¤„ç†æ–‡æœ¬ï¼Œæ›¿æ¢ä¸æ ‡å‡†çš„æ ‡ç‚¹å¹¶æ¸…ç†å¯èƒ½å¯¼è‡´é—®é¢˜çš„å­—ç¬¦
        """
        text = text.replace("ï¼Œ", ",")
        text = text.replace("ã€‚", ",")
        # text = re.sub(r'[\x00-\x1F\x7F]', '', text)
        # text = text.strip("ï¼Œã€‚ï¼ï¼Ÿ")
        print(f"é¢„å¤„ç†åŽçš„æ–‡æœ¬ï¼š{text}")
        return text

    async def start_audio_player(self):
        """å¯åŠ¨å•ä¸€çš„ mpg123 è¿›ç¨‹"""
        if not self.mpg123_process:
            self.mpg123_process = subprocess.Popen(
                ["mpg123", "-"],
                stdin=subprocess.PIPE,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
            logging.info("mpg123 è¿›ç¨‹å¯åŠ¨")

    async def stop_audio_player(self):
        """å…³é—­ mpg123 è¿›ç¨‹"""
        if self.mpg123_process:
            self.mpg123_process.stdin.close()
            self.mpg123_process.wait()
            self.mpg123_process = None
            logging.info("mpg123 è¿›ç¨‹å…³é—­")

    async def stream_tts(self, text):
        if not text.strip():
            logging.warning("æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")
            return
        start_time = time.time()
        communicate = edge_tts.Communicate(text, self.voice)

        async def audio_stream_handler():
            current_audio = io.BytesIO()
            try:
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        current_audio.write(chunk["data"])
                        if current_audio.tell() >= self.min_buffer_size:
                            current_audio.seek(0)
                            await self.audio_queue.put(current_audio.getvalue())
                            current_audio = io.BytesIO()
                if current_audio.tell() > 0:
                    current_audio.seek(0)
                    await self.audio_queue.put(current_audio.getvalue())
                await self.audio_queue.put(None)
            except Exception as e:
                logging.error(f"éŸ³é¢‘æµå¤„ç†é”™è¯¯: {e}")

        async def audio_player():
            await self.start_audio_player()
            try:
                while True:
                    chunk = await self.audio_queue.get()
                    if chunk is None:
                        break
                    try:
                        self.mpg123_process.stdin.write(chunk)
                        self.mpg123_process.stdin.flush()
                    except Exception as e:
                        logging.error(f"éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")
            except Exception as e:
                logging.error(f"éŸ³é¢‘æ’­æ”¾ä»»åŠ¡é”™è¯¯: {e}")

        await asyncio.gather(audio_stream_handler(), audio_player())
        logging.info(f"TTS å¤„ç†è€—æ—¶: {time.time() - start_time:.2f}ç§’")

    async def speak(self, text):
        self.is_speaking = True
        try:
            await self.stream_tts(text)
        except Exception as e:
            logging.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        finally:
            self.is_speaking = False

    async def shutdown(self):
        """æ¸…ç†èµ„æº"""
        await self.stop_audio_player()

async def main():
    # åˆå§‹åŒ– QA å’Œ TTS
    qa = KnowledgeQA()
    tts = EdgeTTSStreaming(voice="zh-CN-XiaoyiNeural")
    
    # æé—®
    question = "ç”˜è–¯çš„è´®è—ç‰¹æ€§"
    logging.info(f"æé—®: {question}")

    # æµå¼å¤„ç†å›žç­”å¹¶å®žæ—¶è¯­éŸ³è¾“å‡º
    buffer = ""
    min_length = 20  # æœ€å°æ–‡æœ¬é•¿åº¦
    trigger_length = 40  # è§¦å‘è¯­éŸ³çš„å­—ç¬¦æ•°
    timeout = 0.5  # 0.5ç§’è¶…æ—¶è§¦å‘è¯­éŸ³
    last_chunk_time = time.time()

    async def text_producer():
        """ä»Ž ask_stream èŽ·å–æ–‡æœ¬å¹¶æ”¾å…¥é˜Ÿåˆ—"""
        async for chunk in qa.ask_stream(question):
            logging.info(f"ðŸ§  è¾“å‡ºå—: {chunk}")
            yield chunk
      
    async def text_consumer():
        """å¤„ç†æ–‡æœ¬å¹¶è§¦å‘è¯­éŸ³"""
        nonlocal buffer, last_chunk_time
        async for chunk in text_producer():
            chunk=tts.preprocess_text(chunk)  # é¢„å¤„ç†æ–‡æœ¬
            buffer += chunk
            last_chunk_time = time.time()

            # è§¦å‘è¯­éŸ³ï¼šè¾¾åˆ° trigger_length æˆ–è¶…æ—¶
            if len(buffer) >= trigger_length or (time.time() - last_chunk_time) >= timeout:
                if len(buffer) >= min_length:
                    logging.info(f"è¯­éŸ³è¾“å‡º: {buffer}")
                    await tts.speak(buffer)
                    buffer = ""  # æ¸…ç©ºç¼“å†²åŒº

        # å¤„ç†å‰©ä½™æ–‡æœ¬
        if buffer and len(buffer) >= min_length:
            logging.info(f"è¯­éŸ³è¾“å‡ºï¼ˆå‰©ä½™ï¼‰: {buffer}")
            await tts.speak('111'+buffer)

    try:
        await text_consumer()
    finally:
        await tts.shutdown()

if __name__ == "__main__":
    asyncio.run(main())