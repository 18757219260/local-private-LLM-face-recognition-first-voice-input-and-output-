# 本地私人 LLM 人脸识别与语音交互系统

本项目整合了本地大语言模型（LLM）、人脸识别、语音输入与输出等多种核心技术，构建了一个专为用户设计的智能交互系统。系统依托本地知识库，通过人脸识别实现个性化问答交互，支持语音命令及语音反馈，适用于如智能农业、智能客服等场景。

---

## 目录

- [系统功能](#系统功能)
- [系统架构](#系统架构)
- [安装与依赖](#安装与依赖)
- [使用说明](#使用说明)
- [配置说明](#配置说明)

---

## 系统功能

- **人脸识别**  
  利用摄像头采集实时视频流，基于 `face_recognition` 等开源库对用户进行人脸检测与识别。支持加载预先注册的多个人脸数据文件（存储于 `images` 目录），可实现动态的身份认证与个性化问答。

- **语音输入与输出**  
  采用 `speech_recognition` 和 `edge_tts` 实现语音识别与语音合成，利用麦克风采集语音命令，并通过扬声器输出语音响应。支持实时交互，改善用户体验。

- **智能问答系统**  
  依托本地知识库（`knowledge.json`）与向量化检索（基于 FAISS），结合本地部署的 LLM（通过 Ollama 接口调用），实现高效、精准的问答交互。系统能够自动检测知识库更新，并对向量库进行更新。

- **交互场景**  
  系统在识别到用户后，会通过语音提示（如“我是你的私人专属甘薯助手，你有什么问题吗？”）启动问答流程，用户可以直接语音提问，系统将给出模型回答，并通过语音反馈。

---

## 系统架构

项目主要由以下模块构成：

1. **主程序（main.py）**  
   采用 `asyncio` 异步编程实现实时检测与交互。主程序循环获取摄像头视频帧，调用人脸识别模块判断是否有新用户，然后启动语音问答流程。

2. **人脸识别模块（face_recognize.py）**  
   封装了摄像头初始化、视频帧获取以及人脸检测、编码与匹配功能。针对分辨率、图像尺寸做了优化，并提供了坐标转换以适配不同显示场景。

3. **问答模型模块（qa_model.py）**  
   负责加载 JSON 格式的知识库，将问答对转换为向量化文档，通过 FAISS 建立本地向量库，利用嵌入模型（HuggingFaceEmbeddings）与本地大语言模型（OllamaLLM）实现检索式问答。此外，支持对话历史管理与知识库更新。

4. **语音输入/输出模块（tts.py）**  
   通过 `speech_recognition` 实现语音录入，通过 `edge_tts` 和 `pygame` 进行语音合成与播放，实现了基于语音的双向交互。

---

## 安装与依赖

### 环境要求

- Python 3.8 及以上
- 摄像头与麦克风（硬件设备）
- 网络环境（用于调用本地 LLM 服务，其接口地址为 `http://localhost:11434`）

### 依赖安装
```bash



1. 克隆项目仓库：
   
   git clone https://github.com/18757219260/local-private-LLM-face-recognition-first-voice-input-and-output.git
   cd local-private-LLM-face-recognition-first-voice-input-and-output
   pip install requirements.txt
```
## 使用说明
# 启动主程序

执行以下命令运行主交互程序：
```bash
python main.py
```
**程序启动后**：

  -  系统将开启摄像头预览窗口，并开始人脸检测。

  - 当识别到注册的人脸后，会通过语音提示启动问答流程。

  -  用户通过语音输入提问，系统通过内部模型获取答案，并通过语音反馈结果。

**单次语音交互测试**

您也可以直接运行语音交互测试模块：
```bash
python tts.py
```
该模块将启动一次语音交互流程，检测语音输入后调用问答模型并返回回答。

## 配置说明

  **人脸识别配置**:<br>
    修改 `face_recognize.py` 内的 `face_map` 字典，可以添加或修改注册的人脸信息，确保图片路径正确。

  **知识库配置**:<br>
    在 `knowledge.json` 中存放问答对，项目会自动读取此文件生成向量库，支持动态更新。更新知识库后，系统会自动检测并重构向量库。

  **语音助手配置**:<br>
    在 `tts.py` 内可以调整语音合成参数，例如语速（rate）、语音风格等，默认使用 `zh-CN-XiaoxiaoNeural` 语音。

  **本地 LLM 接口配置**:<br>
    在 `qa_model.py` 中，默认调用的 LLM 模型为 `EntropyYue/chatglm3`，且接口地址为 `http://localhost:11434`，如有需要请调整相关配置。
